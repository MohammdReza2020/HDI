{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbJ2rXUDhlz7"
      },
      "outputs": [],
      "source": [
        "# HDI-v5 - AE-enabeld ==> Using MNIST as input and device if GPU avaialable\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "############################################################ Target Values\n",
        "#Define the target correlations\n",
        "target_correlations = [0.9, 0.7, 0.5, 0.3, 0.1]\n",
        "\n",
        "# Define target dependence values (adjust as needed)\n",
        "target_dependence = [0.85, 0.65, 0.45, 0.25, 0.15]  # Example values\n",
        "\n",
        "# Under the Gaussian distribution, the correlation coefficient and mutual information have a one-to-one mapping:\n",
        "def rho_to_mi(rho, dim):\n",
        "    result = -dim / 2 * np.log(1 - rho ** 2)\n",
        "    return result\n",
        "\n",
        "def mi_to_rho(mi, dim):\n",
        "    result = np.sqrt(1 - np.exp(-2 * mi / dim))\n",
        "    return result\n",
        "\n",
        "# Calculate target mutual information values from target correlations\n",
        "target_MIs = []\n",
        "for rho in target_correlations:\n",
        "    mi = rho_to_mi(rho, dim=1)  # Assuming 1-dimensional features\n",
        "    target_MIs.append(round(mi, 2))\n",
        "############################################################# Dataset\n",
        "\n",
        "\n",
        "# Define the transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Create DataLoaders for batching\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "############################################################# CUDA Setup\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "######################################################################\n",
        "# ############################################################# Losses\n",
        "# Define the correlation loss\n",
        "def correlation_loss(tensor, target_correlations):\n",
        "    level_1 = tensor[0]  # Level 1\n",
        "    # print('tensor shape = ', tensor.shape)\n",
        "    loss = 0.0\n",
        "    correlations = []\n",
        "    for i, target_corr in enumerate(target_correlations):\n",
        "        # print('i= ',i, 'target_corr= ',target_corr )\n",
        "        level_i = tensor[i + 1]  # Other levels\n",
        "        level_1_flat = level_1.flatten(start_dim=0, end_dim=1)\n",
        "        level_i_flat = level_i.flatten(start_dim=0, end_dim=1)\n",
        "        # print('level_1_flat  shape= ',level_1_flat.shape)\n",
        "        # print('level_i_flat  shape= ',level_i_flat.shape)\n",
        "\n",
        "        # Compute Pearson correlation\n",
        "        cov = torch.mean((level_1_flat - level_1_flat.mean()) * (level_i_flat - level_i_flat.mean()))\n",
        "        std_1 = level_1_flat.std()\n",
        "        std_i = level_i_flat.std()\n",
        "        corr = cov / (std_1 * std_i + 1e-8)\n",
        "        correlations.append(corr.item())  # Store correlation\n",
        "        loss += (corr - target_corr) ** 2\n",
        "\n",
        "    return loss, correlations\n",
        "\n",
        "# Define the independence loss\n",
        "def independence_loss(tensor):\n",
        "    loss = 0.0\n",
        "    levels, batch_size, features = tensor.shape\n",
        "    avg_correlations = []\n",
        "    for level in tensor:\n",
        "        level_corrs = []\n",
        "        for i in range(features):\n",
        "            for j in range(i + 1, features):\n",
        "                col_i = level[:, i]\n",
        "                col_j = level[:, j]\n",
        "                cov = torch.mean((col_i - col_i.mean()) * (col_j - col_j.mean()))\n",
        "                std_i = col_i.std()\n",
        "                std_j = col_j.std()\n",
        "                corr = cov / (std_i * std_j + 1e-8)\n",
        "                level_corrs.append(corr.item())  # Store correlation\n",
        "                loss += corr ** 2  # Penalize non-zero correlations\n",
        "        avg_correlations.append(sum(level_corrs) / len(level_corrs))  # Average correlation for this level\n",
        "    return loss, avg_correlations\n",
        "\n",
        "# Define the mutual information loss\n",
        "def mutual_information_loss(tensor, target_MIs):\n",
        "    level_1 = tensor[0].detach().cpu().numpy()  # Level 1\n",
        "    loss = 0.0\n",
        "    mutual_infos = []\n",
        "    lambda_reg = 0.01  # Regularization parameter\n",
        "\n",
        "    for i, target_corr in enumerate(target_MIs):\n",
        "        level_i = tensor[i + 1].detach().cpu().numpy()  # Other levels\n",
        "\n",
        "        # Flatten the tensors for mutual information calculation\n",
        "        level_1_flat = level_1.reshape(-1)\n",
        "        level_i_flat = level_i.reshape(-1)\n",
        "\n",
        "        # Compute mutual information using sklearn\n",
        "        mi = mutual_info_regression(level_1_flat.reshape(-1, 1), level_i_flat, random_state=42)\n",
        "        mi_value = mi[0] / np.log(2)  # Normalize MI to the range [0, 1]\n",
        "\n",
        "        mutual_infos.append(mi_value)  # Store normalized mutual information\n",
        "        weight = 1.0 if mi_value < target_corr else 0.5  # Dynamic weighting\n",
        "        loss += weight * (mi_value - target_corr) ** 2  # Penalize deviation from target\n",
        "\n",
        "    # Add regularization\n",
        "    loss += lambda_reg * np.sum(np.square(mutual_infos))  # L2 regularization\n",
        "\n",
        "    return loss, mutual_infos\n",
        "\n",
        "# Define the distance correlation function\n",
        "def distance_correlation(x, y):\n",
        "    x = x - x.mean()\n",
        "    y = y - y.mean()\n",
        "\n",
        "    # Compute pairwise distances\n",
        "    a = torch.cdist(x.unsqueeze(0), x.unsqueeze(0), p=2).squeeze()\n",
        "    b = torch.cdist(y.unsqueeze(0), y.unsqueeze(0), p=2).squeeze()\n",
        "\n",
        "    # Double centering\n",
        "    A = a - a.mean(dim=0) - a.mean(dim=1).unsqueeze(1) + a.mean()\n",
        "    B = b - b.mean(dim=0) - b.mean(dim=1).unsqueeze(1) + b.mean()\n",
        "\n",
        "    # Compute distance covariance, variance, and correlation\n",
        "    dcov = torch.sqrt((A * B).mean())\n",
        "    dvar_x = torch.sqrt((A * A).mean())\n",
        "    dvar_y = torch.sqrt((B * B).mean())\n",
        "\n",
        "    return dcov / (torch.sqrt(dvar_x * dvar_y) + 1e-8)\n",
        "\n",
        "# Define the adjacent level dependence loss\n",
        "def adjacent_level_dependence_loss(tensor, target_dependence):\n",
        "    levels, batch_size, features = tensor.shape\n",
        "    loss = 0.0\n",
        "    dependence_values = []\n",
        "\n",
        "    for i in range(levels-1 ):\n",
        "        # print('\\n i= ',i)\n",
        "        level_i = tensor[i].reshape(-1, features)\n",
        "        level_next = tensor[i + 1].reshape(-1, features)\n",
        "\n",
        "        dcorr = distance_correlation(level_i, level_next)\n",
        "        dependence_values.append(dcorr.item())\n",
        "        # print('dependence_values= ',dependence_values)\n",
        "\n",
        "        # Compare to target dependence\n",
        "        if i < len(target_dependence):  # Ensure we have a target value\n",
        "            loss += (dcorr - target_dependence[i])**2\n",
        "    return loss, dependence_values\n",
        "########################################################################## Models\n",
        "# Define the hierarchical bottleneck model\n",
        "class HDI_model(nn.Module):\n",
        "    def __init__(self, levels, features, dropout_rate=0.1, activation=nn.ReLU):\n",
        "        \"\"\"\n",
        "        Enriched Correlation Model for Hierarchical Disentangled Information (HDI).\n",
        "\n",
        "        Args:\n",
        "            levels (int): Number of hierarchical levels.\n",
        "            features (int): Number of features per level.\n",
        "            dropout_rate (float): Dropout rate for regularization.\n",
        "            activation (nn.Module): Activation function to use (default: ReLU).\n",
        "        \"\"\"\n",
        "        super(HDI_model, self).__init__()\n",
        "        self.levels = levels\n",
        "        self.features = features\n",
        "        self.activation = activation()\n",
        "\n",
        "        # Define linear layers for each level (except the first one)\n",
        "        self.linear_layers = nn.ModuleList([\n",
        "            nn.Linear(features, features) for _ in range(levels - 1)\n",
        "        ])\n",
        "\n",
        "        # Define normalization layers for each level\n",
        "        self.norm_layers = nn.ModuleList([\n",
        "            nn.LayerNorm(features) for _ in range(levels - 1)\n",
        "        ])\n",
        "\n",
        "        # Dropout for regularization\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, encoder_output):\n",
        "        \"\"\"\n",
        "        Forward pass through the hierarchical model.\n",
        "        Args:\n",
        "            encoder_output (torch.Tensor): Input tensor from the encoder (shape: [batch_size, features]).\n",
        "        Returns:\n",
        "            torch.Tensor: Stacked tensor of hierarchical levels (shape: [levels, batch_size, features]).\n",
        "        \"\"\"\n",
        "        levels = [encoder_output]  # First level is the encoder output\n",
        "        for i, (layer, norm) in enumerate(zip(self.linear_layers, self.norm_layers)):\n",
        "            # Linear transformation\n",
        "            transformed = layer(levels[-1])\n",
        "            # Add residual connection\n",
        "            residual = transformed + levels[-1]\n",
        "            # Apply normalization\n",
        "            normalized = norm(residual)\n",
        "            # Apply activation function\n",
        "            activated = self.activation(normalized)\n",
        "            # Apply dropout\n",
        "            dropped_out = self.dropout(activated)\n",
        "            # Append to levels\n",
        "            levels.append(dropped_out)\n",
        "        #print('mrh= ',torch.stack(levels).shape) # (levels, batch_size, BN_dim)\n",
        "        # Stack levels into a tensor\n",
        "        return torch.stack(levels)\n",
        "\n",
        "\n",
        "class SimpleHDI(nn.Module):\n",
        "    def __init__(self, levels, features):\n",
        "        \"\"\"\n",
        "        Simple bottleneck that repeats the same level across all levels.\n",
        "        Args:\n",
        "            levels (int): Number of hierarchical levels.\n",
        "            features (int): Number of features per level.\n",
        "        \"\"\"\n",
        "        super(SimpleHDI, self).__init__()\n",
        "        self.levels = levels\n",
        "        self.features = features\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the simple bottleneck.\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, features).\n",
        "        Returns:\n",
        "            torch.Tensor: Bottleneck tensor of shape (levels, batch_size, features),\n",
        "                          where all levels are identical.\n",
        "        \"\"\"\n",
        "        # Repeat the input tensor across the levels dimension\n",
        "        return x.unsqueeze(0).repeat(self.levels, 1, 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################################################\n",
        "\n",
        "# Autoencoder model\n",
        "# class Autoencoder(nn.Module):\n",
        "#     def __init__(self, input_dim, hidden_dim, BN_dim ):\n",
        "#         super(Autoencoder, self).__init__()\n",
        "#         # Encoder\n",
        "#         self.encoder = nn.Sequential(\n",
        "#             nn.Flatten(),\n",
        "#             nn.Linear(28 * 28, hidden_dim[0]),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(hidden_dim[0], hidden_dim[1]),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(hidden_dim[1], latent_dim)\n",
        "#         )\n",
        "#         # Decoder\n",
        "#         self.bottleneck=SimpleBottleneck(levels,BN_dim)  # Hierarchical bottleneck\n",
        "#         self.decoder = nn.Sequential(\n",
        "#             nn.Linear(latent_dim, hidden_dim[1]),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(hidden_dim[1], hidden_dim[0]),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(hidden_dim[0], input_dim),\n",
        "#             nn.Tanh()  # Output normalized to [-1, 1]\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         z = self.encoder(x)\n",
        "#         HDI_levels = self.bottleneck(z)\n",
        "#         #print('HDI_levels= ', HDI_levels.shape) # (levels,batch_size,128)\n",
        "#         # x_reconstructed = self.decoder(z)\n",
        "#         x_reconstructed = self.decoder(HDI_levels)\n",
        "#         return x_reconstructed\n",
        "\n",
        "#########\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Autoencoder2(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, BN_dim, levels):\n",
        "        super(Autoencoder2, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28 * 28, hidden_dim[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim[0], hidden_dim[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim[1], BN_dim)  # Output is (batch_size, BN_dim)\n",
        "        )\n",
        "\n",
        "        # Bottleneck (HDI layer)\n",
        "        # self.bottleneck = SimpleHDI(levels, BN_dim)  # or HDI2(levels, BN_dim)\n",
        "        self.bottleneck = HDI_model(levels, BN_dim)  # or HDI2(levels, BN_dim)\n",
        "\n",
        "        # Attention mechanism to extract one (batch_size, BN_dim) from (levels, batch_size, BN_dim)\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(BN_dim, 1),  # Compute attention score for each level\n",
        "            nn.Softmax(dim=0)      # Normalize scores across levels\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(BN_dim, hidden_dim[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim[1], hidden_dim[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim[0], input_dim),\n",
        "            nn.Tanh()  # Output normalized to [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x, method=\"attention\", fixed_level=0, manual_weights=None):\n",
        "        \"\"\"\n",
        "        Forward pass with a flag to choose the method for extracting (batch_size, BN_dim).\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, input_dim).\n",
        "            method (str): Method to extract (batch_size, BN_dim) from (levels, batch_size, BN_dim).\n",
        "                          Options: \"attention\", \"fixed\", \"weighted\".\n",
        "            fixed_level (int): Index of the level to select if method=\"fixed\".\n",
        "            manual_weights (torch.Tensor): Tensor of shape (levels,) containing weights for levels if method=\"weighted\".\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Reconstructed input of shape (batch_size, input_dim).\n",
        "        \"\"\"\n",
        "        # Encode input\n",
        "        z = self.encoder(x)  # Shape: (batch_size, BN_dim)\n",
        "\n",
        "        # Pass through HDI bottleneck\n",
        "        HDI_levels = self.bottleneck(z)  # Shape: (levels, batch_size, BN_dim)\n",
        "\n",
        "        if method == \"attention\":\n",
        "            # Compute attention scores\n",
        "            attention_scores = self.attention(HDI_levels)  # Shape: (levels, batch_size, 1)\n",
        "            attention_scores = attention_scores.squeeze(-1)  # Shape: (levels, batch_size)\n",
        "\n",
        "            # Weighted sum of levels using attention scores\n",
        "            attention_scores = attention_scores.unsqueeze(-1)  # Shape: (levels, batch_size, 1)\n",
        "            weighted_output = (HDI_levels * attention_scores).sum(dim=0)  # Shape: (batch_size, BN_dim)\n",
        "\n",
        "        elif method == \"fixed\":\n",
        "            # Select a specific level (e.g., first or last)\n",
        "            weighted_output = HDI_levels[fixed_level]  # Shape: (batch_size, BN_dim)\n",
        "\n",
        "        elif method == \"weighted\":\n",
        "            # Use manually provided weights to compute a weighted sum\n",
        "            if manual_weights is None:\n",
        "                raise ValueError(\"manual_weights must be provided when method='weighted'\")\n",
        "            if manual_weights.shape[0] != HDI_levels.shape[0]:\n",
        "                raise ValueError(\"manual_weights must have the same length as the number of levels\")\n",
        "\n",
        "            # Normalize weights to sum to 1\n",
        "            manual_weights = manual_weights / manual_weights.sum()  # Shape: (levels,)\n",
        "            manual_weights = manual_weights.unsqueeze(-1).unsqueeze(-1)  # Shape: (levels, 1, 1)\n",
        "\n",
        "            # Weighted sum of levels\n",
        "            weighted_output = (HDI_levels * manual_weights).sum(dim=0)  # Shape: (batch_size, BN_dim)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid method: {method}. Choose from 'attention', 'fixed', or 'weighted'.\")\n",
        "\n",
        "        # Decode the weighted output\n",
        "        x_reconstructed = self.decoder(weighted_output)  # Shape: (batch_size, input_dim)\n",
        "        return x_reconstructed, HDI_levels\n",
        "############################################################################### Configuration\n",
        "# Hyperparameters\n",
        "input_dim=28*28\n",
        "hidden_dim=[256, 128]\n",
        "levels = 6\n",
        "BN_dim = 5 # Bottleneck features dim\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 10  # Reduced for demonstration\n",
        "\n",
        "################################################################## Initialization\n",
        "# Initialize model, loss, and optimizer\n",
        "\n",
        "\n",
        "\n",
        "# model = Autoencoder(input_dim, hidden_dim, BN_dim).to(device)\n",
        "model= Autoencoder2(input_dim, hidden_dim, BN_dim, levels).to(device)\n",
        "criterion = nn.MSELoss()  # Mean Squared Error for reconstruction\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#####################################################################\n",
        "\n",
        "# Track metrics for plotting\n",
        "correlation_history = []  # To track correlations between levels\n",
        "independence_history = []  # To track average independence correlations\n",
        "mutual_information_history = []  # To track mutual information between levels\n",
        "adjacent_dependence_history = []  # To track adjacent level dependence\n",
        "\n",
        "# Initialize lists to track losses\n",
        "corr_loss_history = []  # To track correlation loss\n",
        "indep_loss_history = []  # To track independence loss\n",
        "mi_loss_history = []\n",
        "adj_loss_history=[]\n",
        "total_loss_history = []  # To track total loss\n",
        "\n",
        "model.train()\n",
        "# Training the autoencoder\n",
        "for epoch in range(num_epochs):\n",
        "    # train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "    train_loss = 0\n",
        "    for images, _ in train_loader:\n",
        "        images = images.to(device)\n",
        "        images = images.view(images.size(0), -1)  # Flatten images\n",
        "\n",
        "        ############################################### Forward pass\n",
        "        # MRH: simple\n",
        "        # output = model(images)\n",
        "\n",
        "        # MRH: Attention\n",
        "        output, HDI_levels = model(images, method=\"attention\")\n",
        "        #print('\\nHDI_levels= ',HDI_levels)\n",
        "\n",
        "        # MRH: Fixed\n",
        "        # output = model(images, method=\"fixed\", fixed_level=3)  # Select the first level\n",
        "        #print('\\nimages shape= ',images.shape) # torch.Size([256, 784])\n",
        "        #print('output shape= ',output.shape) # torch.Size([256, 784])\n",
        "\n",
        "        # MRH: Weighted\n",
        "        # manual_weights = torch.tensor([0.1, 0.2, 0.3, 0.4]).to(device)  # Example weights for 4 levels\n",
        "        # output = model(images, method=\"weighted\", manual_weights=manual_weights)\n",
        "\n",
        "        ############################################# Compute the losses\n",
        "        reconstruction_loss = criterion(output, images)\n",
        "        corr_loss, correlations = correlation_loss(HDI_levels, target_correlations)\n",
        "        indep_loss, avg_independence_corrs = independence_loss(HDI_levels)\n",
        "        # mi_loss, mutual_infos = mutual_information_loss(HDI_levels target_MIs)\n",
        "        adj_loss, dependence_values = adjacent_level_dependence_loss(HDI_levels, target_dependence)\n",
        "\n",
        "        total_loss = reconstruction_loss + corr_loss + 0.1 * indep_loss  + 0.1 * adj_loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        # total_loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        # loss.backward()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        # Track metrics\n",
        "        correlation_history.append(correlations)\n",
        "        independence_history.append(avg_independence_corrs)\n",
        "        # mutual_information_history.append(mutual_infos)\n",
        "        adjacent_dependence_history.append(dependence_values)\n",
        "\n",
        "\n",
        "        # Track losses\n",
        "        corr_loss_history.append(corr_loss.item())\n",
        "        indep_loss_history.append(indep_loss.item())\n",
        "        # mi_loss_history.append(mi_loss.item())\n",
        "        adj_loss_history.append(adj_loss.item())\n",
        "        total_loss_history.append(total_loss.item())\n",
        "\n",
        "        # train_loss += loss.item()\n",
        "        train_loss += total_loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
        "          f\"Reconstruction Loss: {reconstruction_loss.item():.4f}, \"\n",
        "          f\"Correlation Loss: {corr_loss.item():.4f}, Independence Loss: {indep_loss:.4f}, \"\n",
        "          f\"Adjacent Dependence Loss: {adj_loss:.4f}, \"\n",
        "          f\"Total Loss: {total_loss.item():.4f}\")\n",
        "\n",
        "\n",
        "##########\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader:\n",
        "        images = images.to(device)\n",
        "        images = images.view(images.size(0), -1)  # Flatten images\n",
        "        outputs,_ = model(images)\n",
        "images = images.view(-1, 28, 28).cpu().numpy()\n",
        "outputs = outputs.view(-1, 28, 28).cpu().numpy()\n",
        "\n",
        "# Plot original and reconstructed images\n",
        "n = 10  # Number of images to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Original images\n",
        "    plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(images[i], cmap='gray')\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed images\n",
        "    plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(outputs[i], cmap='gray')\n",
        "    plt.title(\"Reconstructed\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "            # return images, outputs  # Return a batch for visualization\n",
        "\n",
        "####################################################\n",
        "fig, axs = plt.subplots(1, 4, figsize=(18, 6))\n",
        "losses = [\n",
        "    (corr_loss_history, \"Correlation Loss\", \"blue\"),\n",
        "    (indep_loss_history, \"Independence Loss\", \"orange\"),\n",
        "    (adj_loss_history, \"Adjacent Dependence Loss\", \"magenta\"),\n",
        "    (total_loss_history, \"Total Loss\", \"green\"),\n",
        "]\n",
        "\n",
        "for i, (loss, title, color) in enumerate(losses):\n",
        "    axs[i].plot(loss, color=color, linewidth=2)\n",
        "    axs[i].set_title(title)\n",
        "    axs[i].set_xlabel(\"Epochs\")\n",
        "    axs[i].set_ylabel(\"Loss\")\n",
        "    axs[i].grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Convert tracked metrics to tensors for easier plotting\n",
        "correlation_history = torch.tensor(correlation_history)\n",
        "independence_history = torch.tensor(independence_history)\n",
        "# mutual_information_history = torch.tensor(mutual_information_history)\n",
        "adjacent_dependence_history = torch.tensor(adjacent_dependence_history)\n",
        "\n",
        "# Plot Correlations Between Levels\n",
        "plt.figure(figsize=(12, 6))\n",
        "colors = ['r', 'g', 'b', 'orange', 'purple']\n",
        "for i, color in enumerate(colors):\n",
        "    plt.plot(correlation_history[:, i], label=f\"Level {i + 2} (Target: {target_correlations[i]})\", color=color, linewidth=2)\n",
        "    plt.axhline(y=target_correlations[i], color=color, linestyle='--', linewidth=1.5)  # Target line\n",
        "plt.title(\"Correlation Between Level 1 and Other Levels\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Correlation\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot Average Independence Correlations Within Levels\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(levels):\n",
        "    plt.plot(independence_history[:, i], label=f\"Level {i + 1}\", linewidth=2)\n",
        "plt.title(\"Average Independence Correlations (Within Levels)\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Average Correlation\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot Mutual Information Between Levels\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# for i, color in enumerate(colors):\n",
        "#     plt.plot(mutual_information_history[:, i], label=f\"Level {i + 2} (Target: {target_MIs[i]})\", color=color, linewidth=2)\n",
        "#     plt.axhline(y=target_MIs[i], color=color, linestyle='--', linewidth=1.5)  # Target line\n",
        "# plt.title(\"Mutual Information Between Level 1 and Other Levels\")\n",
        "# plt.xlabel(\"Epochs\")\n",
        "# plt.ylabel(\"MI\")\n",
        "# plt.legend()\n",
        "# plt.grid()\n",
        "# plt.show()\n",
        "\n",
        "# Plot Dependence Between Adjacent Levels\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, color in enumerate(colors[:-1]):  # Only `levels - 1` adjacent levels\n",
        "    dependence_by_level = [dependence[i] for dependence in adjacent_dependence_history]\n",
        "    plt.plot(dependence_by_level, label=f\"Level {i + 1} vs Level {i + 2}\", color=color, linewidth=2)\n",
        "    plt.axhline(y=target_dependence[i], color=color, linestyle='--', linewidth=1.5)  # Target line\n",
        "plt.title(\"Dependence Between Adjacent Levels\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Dependence (Distance Correlation)\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ]
}
